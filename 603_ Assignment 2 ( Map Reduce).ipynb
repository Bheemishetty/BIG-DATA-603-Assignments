{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0664f14e",
   "metadata": {},
   "source": [
    "# Code Screenshot: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec196b02",
   "metadata": {},
   "source": [
    "1. Write Python code and use MapReduct to count occurrences of each word in the first text file (file.txt). How many times each word is repeated?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e86e963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word counts for file 'file1.txt':\n",
      "the: 88\n",
      "twinkling: 1\n",
      "light: 2\n",
      "that: 17\n",
      "usually: 1\n",
      "shone: 1\n",
      "from: 3\n",
      "Dumbledore’s: 1\n",
      "eyes: 2\n",
      "seemed: 1\n",
      "to: 15\n",
      "have: 4\n",
      "gone: 1\n",
      "out.: 1\n",
      "“Well,”: 1\n",
      "said: 11\n",
      "Dumbledore: 2\n",
      "finally,: 1\n",
      "“that’s: 1\n",
      "that.: 1\n",
      "We’ve: 1\n",
      "no: 4\n",
      "business: 1\n",
      "staying: 1\n",
      "here.: 1\n",
      "We: 1\n",
      "may: 1\n",
      "as: 11\n",
      "well: 1\n",
      "go: 1\n",
      "and: 45\n",
      "join: 1\n",
      "celebrations.”: 1\n",
      "“Yeah,”: 1\n",
      "Hagrid: 2\n",
      "in: 15\n",
      "a: 48\n",
      "very: 6\n",
      "muffled: 1\n",
      "voice,: 1\n",
      "“I’d: 1\n",
      "best: 1\n",
      "get: 2\n",
      "this: 3\n",
      "bike: 2\n",
      "away.: 2\n",
      "G’night,: 1\n",
      "Professor: 4\n",
      "McGonagall: 2\n",
      "—: 8\n",
      "Dumbledore,: 2\n",
      "sir.”: 1\n",
      "Wiping: 1\n",
      "his: 27\n",
      "streaming: 1\n",
      "on: 18\n",
      "jacket: 1\n",
      "sleeve,: 1\n",
      "swung: 1\n",
      "himself: 1\n",
      "onto: 2\n",
      "motorcycle: 2\n",
      "kicked: 1\n",
      "engine: 1\n",
      "into: 5\n",
      "life;: 1\n",
      "with: 9\n",
      "roar: 1\n",
      "it: 12\n",
      "rose: 2\n",
      "air: 1\n",
      "off: 3\n",
      "night.: 1\n",
      "“I: 1\n",
      "shall: 1\n",
      "see: 3\n",
      "you: 8\n",
      "soon,: 1\n",
      "I: 3\n",
      "expect,: 1\n",
      "McGonagall,”: 1\n",
      "nodding: 1\n",
      "her.: 1\n",
      "blew: 1\n",
      "her: 5\n",
      "nose: 1\n",
      "reply.: 1\n",
      "turned: 3\n",
      "walked: 1\n",
      "back: 5\n",
      "down: 4\n",
      "street.: 2\n",
      "On: 1\n",
      "corner: 2\n",
      "he: 26\n",
      "stopped: 1\n",
      "took: 2\n",
      "out: 6\n",
      "silver: 1\n",
      "Put-: 1\n",
      "Outer.: 1\n",
      "He: 13\n",
      "clicked: 1\n",
      "once,: 1\n",
      "twelve: 1\n",
      "balls: 1\n",
      "of: 24\n",
      "sped: 1\n",
      "their: 4\n",
      "street: 1\n",
      "lamps: 1\n",
      "so: 1\n",
      "Privet: 3\n",
      "Drive: 2\n",
      "glowed: 1\n",
      "suddenly: 1\n",
      "orange: 1\n",
      "could: 6\n",
      "make: 1\n",
      "www.ztcprep.com: 10\n",
      "tabby: 1\n",
      "cat: 1\n",
      "slinking: 1\n",
      "around: 1\n",
      "at: 9\n",
      "other: 1\n",
      "end: 1\n",
      "just: 2\n",
      "bundle: 1\n",
      "blankets: 2\n",
      "step: 1\n",
      "number: 2\n",
      "four.: 1\n",
      "“Good: 1\n",
      "luck,: 1\n",
      "Harry,”: 1\n",
      "murmured.: 1\n",
      "heel: 1\n",
      "swish: 1\n",
      "cloak,: 1\n",
      "was: 30\n",
      "gone.: 1\n",
      "A: 1\n",
      "breeze: 1\n",
      "ruffled: 2\n",
      "neat: 1\n",
      "hedges: 1\n",
      "Drive,: 1\n",
      "which: 3\n",
      "lay: 2\n",
      "silent: 1\n",
      "tidy: 2\n",
      "under: 4\n",
      "inky: 1\n",
      "sky,: 1\n",
      "last: 2\n",
      "P: 6\n",
      "g: 6\n",
      "e: 6\n",
      "|: 6\n",
      "18: 1\n",
      "Harry: 27\n",
      "Potter: 9\n",
      "Philosophers: 6\n",
      "Stone: 6\n",
      "–: 6\n",
      "J.K.: 6\n",
      "Rowling: 6\n",
      "place: 1\n",
      "would: 3\n",
      "expect: 1\n",
      "astonishing: 1\n",
      "things: 1\n",
      "happen.: 1\n",
      "rolled: 2\n",
      "over: 5\n",
      "inside: 1\n",
      "without: 1\n",
      "waking: 1\n",
      "up.: 1\n",
      "One: 1\n",
      "small: 2\n",
      "hand: 1\n",
      "closed: 1\n",
      "letter: 1\n",
      "beside: 1\n",
      "him: 4\n",
      "slept: 1\n",
      "on,: 3\n",
      "not: 6\n",
      "knowing: 3\n",
      "special,: 1\n",
      "famous,: 1\n",
      "be: 1\n",
      "woken: 2\n",
      "few: 2\n",
      "hours’: 1\n",
      "time: 3\n",
      "by: 5\n",
      "Mrs.: 3\n",
      "Dursley’s: 1\n",
      "scream: 1\n",
      "she: 6\n",
      "opened: 1\n",
      "front: 4\n",
      "door: 2\n",
      "put: 5\n",
      "milk: 1\n",
      "bottles,: 1\n",
      "nor: 1\n",
      "spend: 1\n",
      "next: 1\n",
      "weeks: 1\n",
      "being: 3\n",
      "prodded: 1\n",
      "pinched: 1\n",
      "cousin: 1\n",
      "Dudley.: 1\n",
      "…: 2\n",
      "couldn’t: 2\n",
      "know: 1\n",
      "moment,: 2\n",
      "people: 1\n",
      "meeting: 1\n",
      "secret: 1\n",
      "all: 8\n",
      "country: 1\n",
      "were: 2\n",
      "holding: 1\n",
      "up: 5\n",
      "glasses: 2\n",
      "saying: 1\n",
      "hushed: 1\n",
      "voices:: 1\n",
      "“To: 1\n",
      "boy: 3\n",
      "who: 3\n",
      "lived!”: 1\n",
      "19: 1\n",
      "THE: 1\n",
      "VANASHIG: 1\n",
      "GLASS: 1\n",
      "Nearly: 1\n",
      "ten: 1\n",
      "years: 2\n",
      "had: 24\n",
      "passed: 1\n",
      "since: 1\n",
      "Dursleys: 1\n",
      "find: 1\n",
      "nephew: 1\n",
      "step,: 1\n",
      "but: 8\n",
      "hardly: 1\n",
      "changed: 1\n",
      "all.: 1\n",
      "The: 5\n",
      "sun: 1\n",
      "same: 3\n",
      "gardens: 1\n",
      "lit: 1\n",
      "brass: 1\n",
      "four: 2\n",
      "Dursleys’: 1\n",
      "door;: 1\n",
      "crept: 1\n",
      "living: 2\n",
      "room,: 1\n",
      "almost: 2\n",
      "exactly: 1\n",
      "been: 6\n",
      "night: 1\n",
      "when: 3\n",
      "Mr.: 1\n",
      "Dursley: 2\n",
      "seen: 1\n",
      "fateful: 1\n",
      "news: 1\n",
      "report: 1\n",
      "about: 3\n",
      "owls.: 1\n",
      "Only: 1\n",
      "photographs: 3\n",
      "mantelpiece: 1\n",
      "really: 2\n",
      "showed: 2\n",
      "how: 3\n",
      "much: 3\n",
      "passed.: 1\n",
      "Ten: 1\n",
      "ago,: 1\n",
      "there: 2\n",
      "lots: 1\n",
      "pictures: 1\n",
      "what: 1\n",
      "looked: 8\n",
      "like: 7\n",
      "large: 3\n",
      "pink: 2\n",
      "beach: 1\n",
      "ball: 1\n",
      "wearing: 1\n",
      "different-colored: 1\n",
      "bonnets: 1\n",
      "Dudley: 15\n",
      "longer: 1\n",
      "baby,: 1\n",
      "now: 1\n",
      "blond: 2\n",
      "riding: 1\n",
      "first: 4\n",
      "bicycle,: 1\n",
      "carousel: 1\n",
      "fair,: 1\n",
      "playing: 1\n",
      "computer: 3\n",
      "game: 1\n",
      "father,: 1\n",
      "hugged: 1\n",
      "kissed: 1\n",
      "mother.: 2\n",
      "room: 1\n",
      "held: 2\n",
      "sign: 1\n",
      "another: 2\n",
      "lived: 2\n",
      "house,: 1\n",
      "too.: 1\n",
      "Yet: 1\n",
      "still: 1\n",
      "there,: 1\n",
      "asleep: 1\n",
      "for: 6\n",
      "long.: 1\n",
      "His: 4\n",
      "Aunt: 8\n",
      "Petunia: 6\n",
      "awake: 1\n",
      "20: 1\n",
      "shrill: 1\n",
      "voice: 1\n",
      "made: 3\n",
      "noise: 1\n",
      "day.: 1\n",
      "“Up!: 1\n",
      "Get: 1\n",
      "up!: 1\n",
      "Now!”: 1\n",
      "woke: 1\n",
      "start.: 1\n",
      "aunt: 3\n",
      "rapped: 1\n",
      "again.: 1\n",
      "“Up!”: 1\n",
      "screeched.: 1\n",
      "heard: 1\n",
      "walking: 1\n",
      "toward: 1\n",
      "kitchen: 3\n",
      "then: 1\n",
      "sound: 1\n",
      "frying: 2\n",
      "pan: 1\n",
      "stove.: 1\n",
      "tried: 1\n",
      "remember: 2\n",
      "dream: 2\n",
      "having.: 1\n",
      "It: 3\n",
      "good: 1\n",
      "one.: 1\n",
      "There: 1\n",
      "flying: 1\n",
      "it.: 2\n",
      "funny: 1\n",
      "feeling: 1\n",
      "he’d: 1\n",
      "before.: 1\n",
      "outside: 1\n",
      "door.: 2\n",
      "“Are: 1\n",
      "yet?”: 1\n",
      "demanded.: 1\n",
      "“Nearly,”: 1\n",
      "Harry.: 1\n",
      "“Well,: 1\n",
      "move: 1\n",
      "want: 2\n",
      "look: 3\n",
      "after: 2\n",
      "bacon.: 2\n",
      "And: 1\n",
      "don’t: 2\n",
      "dare: 1\n",
      "let: 1\n",
      "burn,: 1\n",
      "everything: 1\n",
      "perfect: 1\n",
      "Duddy’s: 1\n",
      "birthday.”: 1\n",
      "groaned.: 1\n",
      "“What: 1\n",
      "did: 1\n",
      "say?”: 1\n",
      "snapped: 1\n",
      "through: 1\n",
      "“Nothing,: 1\n",
      "nothing: 1\n",
      "…”: 2\n",
      "Dudley’s: 6\n",
      "birthday: 2\n",
      "forgotten?: 1\n",
      "got: 1\n",
      "slowly: 1\n",
      "bed: 2\n",
      "started: 1\n",
      "looking: 4\n",
      "socks.: 1\n",
      "found: 1\n",
      "pair: 1\n",
      "and,: 1\n",
      "pulling: 1\n",
      "spider: 1\n",
      "one: 2\n",
      "them,: 2\n",
      "them: 1\n",
      "on.: 1\n",
      "used: 1\n",
      "spiders,: 1\n",
      "because: 4\n",
      "cupboard: 1\n",
      "stairs: 1\n",
      "full: 1\n",
      "where: 1\n",
      "slept.: 1\n",
      "21: 1\n",
      "When: 1\n",
      "dressed: 1\n",
      "went: 2\n",
      "hall: 1\n",
      "kitchen.: 1\n",
      "table: 2\n",
      "hidden: 1\n",
      "beneath: 1\n",
      "presents.: 3\n",
      "though: 1\n",
      "gotten: 2\n",
      "new: 2\n",
      "wanted,: 1\n",
      "mention: 1\n",
      "second: 1\n",
      "television: 1\n",
      "racing: 3\n",
      "bike.: 1\n",
      "Exactly: 1\n",
      "why: 1\n",
      "wanted: 1\n",
      "mystery: 1\n",
      "Harry,: 3\n",
      "fat: 2\n",
      "hated: 2\n",
      "exercise: 1\n",
      "unless: 1\n",
      "course: 1\n",
      "involved: 1\n",
      "punching: 2\n",
      "somebody.: 1\n",
      "favorite: 1\n",
      "bag: 1\n",
      "often: 3\n",
      "catch: 1\n",
      "him.: 1\n",
      "didn’t: 1\n",
      "it,: 1\n",
      "fast.: 1\n",
      "Perhaps: 1\n",
      "something: 1\n",
      "do: 1\n",
      "dark: 1\n",
      "cupboard,: 1\n",
      "always: 1\n",
      "skinny: 1\n",
      "age.: 1\n",
      "even: 1\n",
      "smaller: 1\n",
      "skinnier: 1\n",
      "than: 4\n",
      "wear: 1\n",
      "old: 2\n",
      "clothes: 1\n",
      "Dudley’s,: 1\n",
      "times: 2\n",
      "bigger: 1\n",
      "was.: 1\n",
      "thin: 2\n",
      "face,: 2\n",
      "knobbly: 1\n",
      "knees,: 1\n",
      "black: 1\n",
      "hair,: 1\n",
      "bright: 1\n",
      "green: 1\n",
      "eyes.: 1\n",
      "wore: 1\n",
      "round: 1\n",
      "together: 1\n",
      "lot: 2\n",
      "Scotch: 1\n",
      "tape: 1\n",
      "punched: 1\n",
      "nose.: 1\n",
      "only: 1\n",
      "thing: 1\n",
      "liked: 1\n",
      "own: 1\n",
      "appearance: 1\n",
      "scar: 1\n",
      "forehead: 1\n",
      "shaped: 1\n",
      "bolt: 1\n",
      "lightning.: 1\n",
      "long: 1\n",
      "remember,: 1\n",
      "question: 1\n",
      "ever: 2\n",
      "asking: 1\n",
      "“In: 1\n",
      "car: 1\n",
      "crash: 1\n",
      "your: 2\n",
      "parents: 2\n",
      "died,”: 1\n",
      "said.: 2\n",
      "“And: 2\n",
      "ask: 2\n",
      "questions.”: 1\n",
      "Don’t: 1\n",
      "questions: 1\n",
      "rule: 1\n",
      "quiet: 1\n",
      "life: 1\n",
      "Dursleys.: 1\n",
      "Uncle: 5\n",
      "Vernon: 4\n",
      "entered: 1\n",
      "turning: 1\n",
      "“Comb: 1\n",
      "hair!”: 1\n",
      "barked,: 1\n",
      "way: 2\n",
      "morning: 1\n",
      "greeting.: 1\n",
      "22: 1\n",
      "About: 1\n",
      "once: 1\n",
      "week,: 1\n",
      "top: 1\n",
      "newspaper: 1\n",
      "shouted: 1\n",
      "needed: 1\n",
      "haircut.: 1\n",
      "must: 1\n",
      "more: 2\n",
      "haircuts: 1\n",
      "rest: 1\n",
      "boys: 1\n",
      "class: 1\n",
      "together,: 1\n",
      "difference,: 1\n",
      "hair: 2\n",
      "simply: 1\n",
      "grew: 1\n",
      "place.: 1\n",
      "eggs: 1\n",
      "arrived: 1\n",
      "Vernon.: 1\n",
      "neck,: 1\n",
      "small,: 1\n",
      "watery: 1\n",
      "blue: 1\n",
      "eyes,: 1\n",
      "thick: 1\n",
      "smoothly: 1\n",
      "thick,: 1\n",
      "head.: 1\n",
      "baby: 1\n",
      "angel: 1\n",
      "pig: 1\n",
      "wig.: 1\n",
      "plates: 1\n",
      "egg: 1\n",
      "bacon: 2\n",
      "table,: 1\n",
      "difficult: 1\n",
      "wasn’t: 1\n",
      "room.: 1\n",
      "Dudley,: 2\n",
      "meanwhile,: 1\n",
      "counting: 1\n",
      "face: 1\n",
      "fell.: 1\n",
      "“Thirty-six,”: 1\n",
      "said,: 1\n",
      "mother: 1\n",
      "father.: 2\n",
      "“That’s: 1\n",
      "two: 3\n",
      "less: 1\n",
      "year.”: 1\n",
      "“Darling,: 1\n",
      "haven’t: 1\n",
      "counted: 1\n",
      "Auntie: 1\n",
      "Marge’s: 1\n",
      "present,: 1\n",
      "see,: 1\n",
      "it’s: 1\n",
      "here: 1\n",
      "big: 1\n",
      "Mommy: 1\n",
      "Daddy.”: 1\n",
      "“All: 2\n",
      "right,: 1\n",
      "thirty-seven: 1\n",
      "then,”: 1\n",
      "going: 1\n",
      "red: 1\n",
      "face.: 1\n",
      "huge: 1\n",
      "tantrum: 1\n",
      "coming: 1\n",
      "began: 1\n",
      "wolfing: 1\n",
      "fast: 1\n",
      "possible: 1\n",
      "case: 1\n",
      "over.: 1\n",
      "obviously: 1\n",
      "scented: 1\n",
      "danger,: 1\n",
      "too,: 1\n",
      "quickly,: 1\n",
      "we’ll: 1\n",
      "buy: 1\n",
      "presents: 1\n",
      "while: 2\n",
      "we’re: 1\n",
      "today.: 1\n",
      "How’s: 1\n",
      "that,: 1\n",
      "popkin?: 1\n",
      "Two: 1\n",
      "Is: 1\n",
      "right?”: 1\n",
      "23: 1\n",
      "thought: 1\n",
      "moment.: 1\n",
      "hard: 1\n",
      "work.: 1\n",
      "Finally: 1\n",
      "slowly,: 1\n",
      "“So: 1\n",
      "I’ll: 1\n",
      "thirty: 2\n",
      "“Thirty-nine,: 1\n",
      "sweetums,”: 1\n",
      "Petunia.: 1\n",
      "“Oh.”: 1\n",
      "sat: 1\n",
      "heavily: 1\n",
      "grabbed: 1\n",
      "nearest: 1\n",
      "parcel.: 1\n",
      "right: 1\n",
      "then.”: 1\n",
      "chuckled.: 1\n",
      "“Little: 1\n",
      "tyke: 1\n",
      "wants: 1\n",
      "money’s: 1\n",
      "worth,: 1\n",
      "’Atta: 1\n",
      "boy,: 1\n",
      "Dudley!”: 1\n",
      "hair.: 1\n",
      "At: 1\n",
      "moment: 1\n",
      "telephone: 2\n",
      "rang: 1\n",
      "answer: 1\n",
      "watched: 1\n",
      "unwrap: 1\n",
      "bike,: 1\n",
      "video: 1\n",
      "camera,: 1\n",
      "remote: 1\n",
      "control: 1\n",
      "airplane,: 1\n",
      "sixteen: 1\n",
      "games,: 1\n",
      "VCR.: 1\n",
      "ripping: 1\n",
      "paper: 1\n",
      "gold: 1\n",
      "wristwatch: 1\n",
      "came: 1\n",
      "both: 1\n",
      "angry: 1\n",
      "worried.: 1\n",
      "“Bad: 1\n",
      "news,: 1\n",
      "Vernon,”: 1\n",
      "“Mrs.: 1\n",
      "Figg’s: 1\n",
      "broken: 1\n",
      "leg.: 1\n",
      "She: 2\n",
      "can’t: 1\n",
      "take: 1\n",
      "him.”: 1\n",
      "jerked: 1\n",
      "head: 1\n",
      "Harry’s: 2\n",
      "direction.: 1\n",
      "mouth: 1\n",
      "fell: 1\n",
      "open: 1\n",
      "horror,: 1\n",
      "heart: 1\n",
      "gave: 1\n",
      "leap.: 1\n",
      "Every: 2\n",
      "year: 1\n",
      "birthday,: 1\n",
      "friend: 1\n",
      "day,: 1\n",
      "adventure: 1\n",
      "parks,: 1\n",
      "hamburger: 1\n",
      "restaurants,: 1\n",
      "or: 1\n",
      "movies.: 1\n",
      "year,: 1\n",
      "left: 1\n",
      "behind: 1\n",
      "Figg,: 1\n",
      "mad: 1\n",
      "lady: 1\n",
      "streets: 1\n",
      "there.: 1\n",
      "whole: 1\n",
      "house: 1\n",
      "smelled: 1\n",
      "cabbage: 1\n",
      "Figg: 1\n",
      "cats: 1\n",
      "she’d: 1\n",
      "owned.: 1\n",
      "“Now: 1\n",
      "what?”: 1\n",
      "Petunia,: 1\n",
      "furiously: 1\n"
     ]
    }
   ],
   "source": [
    "#Birthdate: 30-jan-1999\n",
    "\n",
    "# importing the necessary libraries\n",
    "from functools import reduce\n",
    "\n",
    "# choosing the  file path\n",
    "file_path = \"file1.txt\"\n",
    "\n",
    "#  function to split the string into words\n",
    "def split_words(string):\n",
    "    return string.split()\n",
    "\n",
    "# Read the file and split it into words\n",
    "with open(file_path, \"r\") as file:\n",
    "    words = file.read().split()\n",
    "\n",
    "# Use map to create a list of tuples (word, 1)\n",
    "word_count_pairs = list(map(lambda x: (x, 1), words))\n",
    "\n",
    "# Use reduce to sum the counts for each word\n",
    "def count_words(word_counts, word_count_pair):\n",
    "    word, count = word_count_pair\n",
    "    word_counts[word] = word_counts.get(word, 0) + count\n",
    "    return word_counts\n",
    "\n",
    "# Use reduce to sum the counts for each word\n",
    "word_counts = reduce(count_words, word_count_pairs, {})\n",
    "\n",
    "# Print the result\n",
    "print(f\"Word counts for file '{file_path}':\")\n",
    "for word, count in word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310179ee",
   "metadata": {},
   "source": [
    " 2. From the second text file (file2.txt), write Python code and use MapReduct to count how many times non-English words (names, places, spells etc.) were used. List those words and how many times each was repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d61cae21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyenchant in c:\\users\\babas\\anaconda3\\lib\\site-packages (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyenchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a4b9439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-English words and their counts:\n",
      "JK 9\n",
      "wouldnt 1\n",
      "wizarding 1\n",
      "theyd 2\n",
      "Hagrid 23\n",
      "Im 4\n",
      "Dursley 1\n",
      "Vernons 1\n",
      "Thats 2\n",
      "wwwztcprepcom 11\n",
      "KnowWho 1\n",
      "yeh 7\n",
      "mystry 1\n",
      "gettin 2\n",
      "whyd 1\n",
      "bidin 1\n",
      "couldve 1\n",
      "comin 1\n",
      "somethin 3\n",
      "goin 2\n",
      "hadnt 3\n",
      "Hed 1\n",
      "hed 2\n",
      "dont 1\n",
      "Dudleys 1\n",
      "Hadnt 1\n",
      "youll 1\n",
      "wasnt 2\n",
      "Havent 1\n",
      "Ive 1\n",
      "Albus 1\n",
      "Dumbled 1\n",
      "ALBUS 1\n",
      "Shouldnta 1\n",
      "didnt 5\n",
      "speakin 1\n",
      "arent 1\n",
      "meself 1\n",
      "weve 1\n",
      "DIAGON 1\n",
      "Hagrids 3\n",
      "Dont 2\n",
      "Theres 1\n",
      "payin 1\n",
      "deliverin 1\n",
      "strangelooking 1\n",
      "Knuts 2\n",
      "havent 1\n",
      "Dyeh 1\n",
      "didn 1\n",
      "Gringotts 2\n",
      "theyre 1\n",
      "wouldn 1\n",
      "teh 1\n",
      "yehd 1\n"
     ]
    }
   ],
   "source": [
    "import enchant\n",
    "from functools import reduce\n",
    "import re\n",
    "\n",
    "# create an instance of the English dictionary\n",
    "d = enchant.Dict(\"en_US\")\n",
    "\n",
    "# map function\n",
    "def map_func(word):\n",
    "    word = re.sub('[^a-zA-Z]', '', word)  # remove non-alphabetic characters\n",
    "    if word and not d.check(word):\n",
    "        return (word, 1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# reduce function\n",
    "def reduce_func(acc, curr):\n",
    "    if curr is not None:\n",
    "        word, count = curr\n",
    "        if word in acc:\n",
    "            acc[word] += count\n",
    "        else:\n",
    "            acc[word] = count\n",
    "    return acc\n",
    "\n",
    "# read the file\n",
    "with open('file2.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# split the text into words\n",
    "words = text.split()\n",
    "\n",
    "# map step\n",
    "mapped = map(map_func, words)\n",
    "\n",
    "# reduce step\n",
    "reduced = reduce(reduce_func, mapped, {})\n",
    "\n",
    "# print the non-English words and their counts\n",
    "print(\"Non-English words and their counts:\")\n",
    "for word, count in reduced.items():\n",
    "    print(word, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9767b78d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
